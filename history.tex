\textbf{В 1948 году}, исследуя проблему рациональной передачи информации через зашумлённый коммуникационный канал, \textbf{Клод Шеннон} предложил революционный вероятностный подход к пониманию коммуникаций и создал первую, истинно математическую, теорию энтропии. 
\\


Его сенсационные идеи быстро послужили основой разработки двух основных направлений: \textit{теории информации}, которая использует понятие вероятности для изучения статистических характеристик данных и коммуникационных систем, и \textit{теории кодирования}, в которой используются главным образом алгебраические и геометрические инструменты для разработки эффективных кодов.
\\


Понятие энтропии, как меры случайности, введено Шенноном в его статье \textit{«Математическая теория связи»} (англ. A Mathematical Theory of Communication), опубликованной в двух частях в Bell System Technical Journal в 1948 году.
\\


В случае равновероятных событий (частный случай), остается зависимость только от количества рассматриваемых вариантов, и формула Шеннона значительно упрощается и совпадает с \textit{формулой Хартли}, которая впервые была предложена американским инженером \textbf{Ральфом Хартли в 1928 году}, как один из научных подходов к оценке сообщений:

\[I=-\log p = \log N ,\]
где $I$ – количество передаваемой информации, $p$ – вероятность события, $N$ – возможное количество различных (равновероятных) сообщений.